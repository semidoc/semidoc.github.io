<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Semidoc</title>
    <description>Blog du séminaire des doctorants de l’IRIF à l’université Paris Diderot.</description>
    <link>https://semidoc.github.io/</link>
    <atom:link href="https://semidoc.github.io//feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>No tiling by convex heptagons</title>
        <description>&lt;p&gt;Fourth post of the GT CoA series, see 
&lt;a href=&quot;https://semidoc.github.io/information-communication&quot;&gt;here&lt;/a&gt; for the introduction.&lt;/p&gt;

&lt;p&gt;The talk related to this post was given by 
&lt;a href=&quot;https://perso.ens-lyon.fr/michael.rao/&quot;&gt;Michaël Rao&lt;/a&gt; on his recent result 
about &lt;a href=&quot;https://en.wikipedia.org/wiki/Pentagonal_tiling&quot;&gt;pentagonal tilings&lt;/a&gt;. 
This topic has been covered in many places (see for example
&lt;a href=&quot;https://www.quantamagazine.org/pentagon-tiling-proof-solves-century-old-math-problem-20170711/&quot;&gt;Quanta magazine&lt;/a&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 
and this &lt;a href=&quot;https://lejournal.cnrs.fr/videos/le-theoreme-du-carreleur&quot;&gt;video&lt;/a&gt;. 
This post will focus on another aspect: what about heptagonal tilings?
More precisely, how to show that there is no tiling of the plane with a convex 
heptagonal tile?&lt;/p&gt;

&lt;p&gt;We first present a simple heurisitic proof that gives the intuition about why this holds, 
and then a more detailed proof. The first one uses simple geometry, the second is 
graph theoretical.&lt;/p&gt;

&lt;h1 id=&quot;first-heuristic-proof-via-double-counting-of-the-angles&quot;&gt;First (heuristic) proof via double-counting of the angles&lt;/h1&gt;

&lt;p&gt;Let a &lt;em&gt;contact point&lt;/em&gt; be a place where three or more tiles meet. Without loss of 
generality wa can assume that tiles only meet at vertices, that is there is no 
contact point in the interior of an edge, it is always at an endpoint.&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;As the &lt;a href=&quot;https://en.wikipedia.org/wiki/Polygon#Angles&quot;&gt;sum of the interior angles of an $n$-gon&lt;/a&gt; 
is $(n-2)\times 180$ degrees, for an heptagon it is $5\times 180=900$ degrees. 
The average degree is $900/7\approx 129$ degrees. Which means that at one 
contact point there are in average $360/129\approx 2.8 $ heptagons meeting. 
This does not make sense because at every contact point there should be at least 
three tiles.&lt;/p&gt;

&lt;h1 id=&quot;second-proof-with-planar-graphs&quot;&gt;Second proof with planar graphs.&lt;/h1&gt;

&lt;h2 id=&quot;first-attempt-via-the-degree&quot;&gt;First attempt via the degree&lt;/h2&gt;
&lt;p&gt;Take an infinite tiling, and draw the following graph. In the middle of each 
tile draw a vertex, and between two vertices that represent adjacent tiles, draw 
an edge. This graph is infinite and planar. As the tiles are convex, there are at 
least seven different tiles adjacent to it, and then the minimum degree of a 
vertex in the graph is seven.&lt;/p&gt;

&lt;p&gt;If you are used to planar graphs, you may think that this is enough to conclude. 
Indeed, it is known that the average degree of panar graphs is strictly smaller 
than six 
(see for example &lt;a href=&quot;https://en.wikipedia.org/wiki/Planar_graph#Average_degree&quot;&gt;here&lt;/a&gt;), 
and the contradiction follows. Actually this is not enough because this average 
degree upper bound holds only in finite graph. As a counter-example to this in 
infinite graphs, consider an infinite regular tree with arbitrary large degree $d$ ; 
it is a planar graph and it has average degree $d$.&lt;/p&gt;

&lt;h2 id=&quot;euler-formula-on-the-dual&quot;&gt;Euler formula on the dual&lt;/h2&gt;
&lt;p&gt;The degree bound comes form the classic tool for planar graphs,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Euler_characteristic#Plane_graphs&quot;&gt;Euler’s formula&lt;/a&gt;. 
It states that  $|V|-|E|+|F|=2$ for finite planar graphs, where $V$ is the set of 
nodes, $E$ is the set of edges, and $F$ is the set of faces. The problem 
is that it works only for finite graphs. We will consider a large enough part of 
the infinite graph and use Euler formula to prove the result.&lt;/p&gt;

&lt;p&gt;This can probably be achieved in the graph we have defined, but it is more 
convenient on its dual. Given a tiling, consider every place where three 
or more tiles meet as a vertex, and the edges of the tiles are the edges of the 
graph. Basically drawing the tiling is drawing the graph.&lt;/p&gt;

&lt;p&gt;Now consider a ball of radius $r$ much larger than the size of the tile, and the 
tiles that are at least partilly in this ball. There 
is order of $r^2$ tiles strictly inside the ball and $O(r)$ tiles at the boundary.
Note that the tiles are the faces of the planar graph (except the outer face 
that is not a tile). A similar thing holds for 
vertices: there are $\Theta(r)$ vertices that are at the boundary, call them 
boundary nodes ($V_b$), and order of  $r^2$ that are strictly inside the graph, 
called interior nodes ($V_i$).&lt;/p&gt;

&lt;p&gt;We double-count edges. For every edge, divide it lengthwise into two 
half-edges. There are clearly $2|E|$ half-edges. Also every face except the 
outerface is a tile, so contributes seven half-edges. The number of half-edges 
of the outerface is in $O(r)$. Thus $2|E|=7|F|+O(r)$.&lt;/p&gt;

&lt;p&gt;We now count the corners (or interior angles) of tiles. Every tile has seven 
corners, thus this number is exactly $7|F|$. As every interior node contributes 
at least three corners, $7|F|\geq 3|V_i|$.&lt;/p&gt;

&lt;p&gt;Now using that $|V|=|V_i|+|V_b|$, then $|E|=\frac{7}{2}|F|+O(r)$ and finally 
$|F|\geq \frac{3}{7}|V_i|$ one gets: $-\frac{15}{14}V_i+V_b-O(r)\geq 2$. This is 
not possible because $V_i$ has a higher order of magnitude than the two other 
terms, thus the asymptotics should go to $-\infty$.&lt;/p&gt;

&lt;h4 id=&quot;notes-et-footnotes&quot;&gt;Notes et footnotes&lt;/h4&gt;
&lt;p&gt;Thanks to Michaël Rao for discussions.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;There exists a translation in French, in &lt;a href=&quot;https://www.pourlascience.fr/sd/mathematiques/un-point-final-au-probleme-des-pavages-pentagonaux-du-plan-12669.php&quot;&gt;Pour la science&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;This would need a proof, but roughly, having a contact point in the middle of an edge only make the argument stronger, as it forces the other angles to be small.&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Fri, 09 Mar 2018 00:00:00 +0100</pubDate>
        <link>https://semidoc.github.io///heptagons</link>
        <guid isPermaLink="true">https://semidoc.github.io///heptagons</guid>
      </item>
    
      <item>
        <title>Greedy algorithm for maximum independent set</title>
        <description>&lt;p&gt;One more post of our GT CoA series. The introductory post is 
&lt;a href=&quot;https://semidoc.github.io/information-communication&quot;&gt;here&lt;/a&gt;. 
We skip the third talk, &lt;em&gt;Lempel-Ziv: a “one-bit catastrophe” but not a tragedy&lt;/em&gt; 
because we have already covered this paper, see 
&lt;a href=&quot;https://semidoc.github.io/lagarde-catastrophe&quot;&gt;this post&lt;/a&gt;. The fourth talk of 
the meeting was about greedy algorithms for maximum independent set, presented 
by &lt;a href=&quot;http://www.di.ens.fr/~mmari/index.html&quot;&gt;Mathieu Mari&lt;/a&gt;. Once again, the text 
will not deal much with the actual  work of the speaker, but more with the 
background of it.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;maximum-independent-sets-are-hard-to-find&quot;&gt;Maximum independent sets are hard to find&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Independent_set_(graph_theory)&quot;&gt;Maximum independent set&lt;/a&gt; 
is an algorithmic problem, which asks to find the maximum set of nodes of the 
input graph such that not two nodes of the set are adjacent. As the problem is 
&lt;a href=&quot;https://en.wikipedia.org/wiki/NP-hardness&quot;&gt;NP-hard&lt;/a&gt;, one naturally look for 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Approximation_algorithm&quot;&gt;approximation algorithms&lt;/a&gt;. 
Unfortunately it is impossible to design a non-trivial polynomial-time 
approximation algorithm, unless you know what happens&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;On the other hand, these hardness results are for worst-case general graphs, and 
it is still interesting to study the behaviour of very simple algorithms. 
This post is about greedy algorithms.&lt;/p&gt;

&lt;h2 id=&quot;a-greedy-algorithm-and-when-it-fails&quot;&gt;A greedy algorithm and when it fails&lt;/h2&gt;
&lt;p&gt;A greedy algorithm for maximum independent set is the following:&lt;/p&gt;

&lt;p&gt;Start with all nodes unlabelled.&lt;br /&gt;
Until all nodes are labelled:&lt;br /&gt;
    Choose an unlabelled node with the minimum of unlabelled neighbours; &lt;br /&gt;
    Label this node with 1, and its unlabelled neighbours with 0; &lt;br /&gt;
Output the set of nodes labelled with 1.&lt;/p&gt;

&lt;p&gt;The idea of choosing a node whose degree in the remaining unlabelled part of the 
graph comes 
from a simple intuition: if I choose a node with high degree, I will label 
a lot of nodes in one step, which is bad because it decreases a lot the 
number of nodes that are candidates to be in the independent set. But because of 
what we said before, we know that this has to fail sometimes. Here is an example. 
There are three sets of nodes : ${x}$, ${a_1,…., a_k}$ and 
${b_1,…,b_k}$. The vertex $x$ is linked to every $a_i$, every 
$a_i$ is linked to every $b_j$, and the $b_j$ form a clique. On this graph, the 
algorithm will first pick $x$, and then pick a node 
in ${b_1,…,b_k}$, and stop. The independent set returned has size 2, but 
${a_1,…., a_k}$ is an independent set of size $k$, therefore the approximation 
ratio is roughly the size of the instance.&lt;/p&gt;

&lt;h2 id=&quot;and-when-it-succeeds&quot;&gt;And when it succeeds&lt;/h2&gt;
&lt;p&gt;The first thing one can say about this graph, is that it uses very high degree 
nodes. What happens if we consider bounded degree graphs? Then for maximum degree 
$\Delta$, greedy achieves the approximation of ratio $\frac{\Delta+2}{3}$&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, 
which is not that bad. 
A second thing one can say, is that this graph does not seem generic, for example 
it does not look like a 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93R%C3%A9nyi_model&quot;&gt;random graph&lt;/a&gt;. 
And greedy is quite good on random graphs 
actually, it achieves a ratio 2 in expectation&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Random graph are not that common in applications though, either on real-world 
graphs or on network architecture. What about trees, what about planar graphs? 
Once again greedy is a good choice: it provides a 6-approximation on planar 
graphs, and is optimal for trees.&lt;/p&gt;

&lt;p&gt;There is a general method to prove that greedy is optimal for 
trees, and also on other graph classes, such as 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Outerplanar_graph&quot;&gt;maximal outerplanar graphs&lt;/a&gt;, 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Cograph&quot;&gt;cographs&lt;/a&gt;, and 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Split_graph&quot;&gt;split graphs&lt;/a&gt;. 
First note that if there is a node $v$ in the graph 
such that its neighbours and itself form a clique, then this node belongs to one of 
the maximum independent sets. Indeed only one node from the clique can be in the 
set, and we can always take the node $v$, because there cannot be a conflict 
with a node outside the clique. If the class of graphs at hand has the property 
that the nodes with the lowest degree have such clique neighbourhoods, then the 
greedy algorithm never makes a bad choice, and is optimal. In trees, the lowest 
degree nodes are the leaves, and they have such a property, because they have 
only one neighbour, thus the greedy algorithm is optimal.&lt;/p&gt;

&lt;h2 id=&quot;how-good-is-greedy-on-a-particular-graph&quot;&gt;How good is greedy on a particular graph?&lt;/h2&gt;
&lt;p&gt;Ok, so greedy can be very bad, but it can also be good. And this can depend not 
only on the graph but also on the choices made by the algorithm : at every step 
there can be several nodes with minimum degree, and the choice can dramatically 
change the output. But can we predict how good or bad greedy can be? Can we 
know which execution of the algorithm will give the best outcome, without 
running it ? Mathieu and his co-author’s answer is basically “no”.&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Some precisions about the non-approximability results. The precise results is that it is NP-hard to get a $n^{1-\epsilon}$ approximation of the maximum independent set. It comes from the paper &lt;a href=&quot;https://pdfs.semanticscholar.org/5be6/a7e25c5e4cb0f1ece182042dc6275e438bbd.pdf&quot;&gt;Clique is hard to approximate within $n^{1–\epsilon}$&lt;/a&gt; by &lt;a href=&quot;https://en.wikipedia.org/wiki/Johan_H%C3%A5stad&quot;&gt;Johan Håstad&lt;/a&gt; and is proved with the &lt;a href=&quot;https://en.wikipedia.org/wiki/PCP_theorem&quot;&gt;PCP machinery&lt;/a&gt;. Note that the title of the paper is about the maximum clique problem and not the independent set, but for general graphs this is the same problem: just take the complement of the input graph.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;See &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.5619&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Greed is good: Approximating independent sets in sparse and bounded-degree graphs&lt;/a&gt; by Halldórsson and Radhakrishnan.&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;See &lt;a href=&quot;https://arxiv.org/pdf/1007.1378&quot;&gt;On independent sets in random graphs&lt;/a&gt; by Coja-Oghlan and Efthymiou.&amp;nbsp;&lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 29 Jan 2018 00:00:00 +0100</pubDate>
        <link>https://semidoc.github.io///greedyMIS</link>
        <guid isPermaLink="true">https://semidoc.github.io///greedyMIS</guid>
      </item>
    
      <item>
        <title>Magazines, rubriques et cie.</title>
        <description>&lt;p&gt;Hi, this post is in French (except this paragraph, as you may
have noticed) and is a list of magazines or websites related to TCS.
Some of these are written in French, others in English.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Bonjour, en complément au &lt;a href=&quot;https://semidoc.github.io/blogs&quot;&gt;billet sur les blogs&lt;/a&gt; 
publié ici il y a quelques mois,
un billet sur des initiatives plus structurées qui traitent (entre autres) d’informatique
théorique : des magazines, des rubriques dans des journaux, 
des blogs d’institutions.&lt;/p&gt;

&lt;h3 id=&quot;quanta-magazinehttpswwwquantamagazineorg&quot;&gt;&lt;a href=&quot;https://www.quantamagazine.org/&quot;&gt;Quanta magazine&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Un magazine en ligne parlant de sciences en générale, mais assez souvent
d’informatique théorique, et plutôt bien&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, malgré des titres 
un peu sensationnels parfois&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. La plupart des
sujets sont reliés au quantique ou à l’apprentissage, mais pas tous. Le
magazine est financé par la fondation Simons, qui est aussi à l’origine
du &lt;a href=&quot;https://simons.berkeley.edu/&quot;&gt;Simons Institute for the Theory of Computing&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;images-des-mathshttpimagesmathcnrsfrlangfr&quot;&gt;&lt;a href=&quot;http://images.math.cnrs.fr/?lang=fr&quot;&gt;Images des maths&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Images des maths&lt;/em&gt; est une plate-forme de vulgarisation des mathématiques
(au sens large) soutenue par le CNRS. Les articles sont écrits par des
profs et chercheurs, et sont de difficulté variable (celle-ci étant annoncée par 
un code couleur). Il y est question d’informatique théorique relativement
souvent, et il y aussi un bonne revue de presse tous les mois.&lt;/p&gt;

&lt;h3 id=&quot;binairehttpbinairebloglemondefr&quot;&gt;&lt;a href=&quot;http://binaire.blog.lemonde.fr/&quot;&gt;Binaire&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Le blog du &lt;em&gt;Monde&lt;/em&gt; sur l’informatique, soutenue par la Société
Informatique de France. Le blog suit l’actualité de l’informatique en 
donnant un point de vue un peu plus axé « recherche » que dans les médias et 
blogs généralistes. Et 
aussi : des podcasts, de l’histoire de l’informatique, des rubriques
récurrentes
(notamment 
« &lt;a href=&quot;http://binaire.blog.lemonde.fr/il-etait-une-fois-ma-these/&quot;&gt;Il était une fois ma thèse…&lt;/a&gt; »).&lt;/p&gt;

&lt;h3 id=&quot;intersticeshttpsintersticesinfo&quot;&gt;&lt;a href=&quot;https://interstices.info/&quot;&gt;Interstices&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Magazine en ligne du numérique, soutenu par Inria. Des articles rédigés 
par des chercheurs, là encore sur les sujets du moment, l’histoire de 
l’informatique etc. mais aussi des billets de vulgarisation sur des 
sujets peu plus pointus, dans la section 
« &lt;a href=&quot;https://interstices.info/jcms/mf_46683/approfondir&quot;&gt;Approfondir&lt;/a&gt; ».&lt;/p&gt;

&lt;h3 id=&quot;et-sur-papier&quot;&gt;Et sur papier…&lt;/h3&gt;
&lt;p&gt;Plusieurs journaux scientifiques francophones ont des rubriques
pertinentes pour ce post. Notamment :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.pourlascience.fr/ewb_pages/l/logique_et_calcul.php&quot;&gt;Logique et calcul&lt;/a&gt;
de &lt;a href=&quot;https://fr.wikipedia.org/wiki/Jean-Paul_Delahaye&quot;&gt;Jean-Paul Delahaye&lt;/a&gt;
dans &lt;em&gt;&lt;a href=&quot;https://fr.wikipedia.org/wiki/Pour_la_science&quot;&gt;Pour la science&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;la chronique « Numériques »  tenues par 
Serge Abiteboul et Gerard Berry, et la chronique « Mathématiques » de 
Roger Mansuy, dans &lt;em&gt;&lt;a href=&quot;http://www.larecherche.fr/&quot;&gt;La Recherche&lt;/a&gt;&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;notes&quot;&gt;Notes&lt;/h4&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Voir par exemple &lt;a href=&quot;https://www.quantamagazine.org/one-way-salesman-finds-fast-path-home-20171005/&quot;&gt;l’article&lt;/a&gt; sur les récentes avancées sur le problème du voyageur de commerce que l’on citait dans le &lt;a href=&quot;https://semidoc.github.io/cubic-TSP&quot;&gt;billet précédent&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;Comme « &lt;em&gt;&lt;a href=&quot;https://www.quantamagazine.org/subhash-khot-unique-games-conjecturer-is-awarded-rolf-nevanlinna-prize-20140812/&quot;&gt;A Grand Vision for the Impossible&lt;/a&gt;&lt;/em&gt; » pour un article sur la &lt;a href=&quot;https://fr.wikipedia.org/wiki/Conjecture_des_jeux_uniques&quot;&gt;conjecture des jeux uniques&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 15 Jan 2018 00:00:00 +0100</pubDate>
        <link>https://semidoc.github.io///mags</link>
        <guid isPermaLink="true">https://semidoc.github.io///mags</guid>
      </item>
    
      <item>
        <title>Travelling salesman problem on cubic graphs</title>
        <description>&lt;p&gt;This is the second post of a series that start
&lt;a href=&quot;https://semidoc.github.io/information-communication&quot;&gt;here&lt;/a&gt;, based on the talks 
given at a French meeting on algorithms and complexity 
(&lt;a href=&quot;https://www.irif.fr/~nschaban/GT-COA/&quot;&gt;GT CoA&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The second talk I want to “review” is: &lt;em&gt;Applications and Constructions of cut-covering 
decompositions for connectivity problems&lt;/em&gt;, by 
&lt;a href=&quot;http://www.g-scop.grenoble-inp.fr/membres/newman-alantha--570520.kjsp&quot;&gt;Alantha Newman&lt;/a&gt; from the 
&lt;a href=&quot;http://www.g-scop.grenoble-inp.fr/welcome/welcome--452610.kjsp&quot;&gt;GSOP lab&lt;/a&gt; in 
Grenoble. Her work is partly based on an approch that began with the paper
 &lt;em&gt;&lt;a href=&quot;http://dare.ubvu.vu.nl/bitstream/handle/1871/34734/274155.pdf?sequence=1&quot;&gt;TSP on Cubic and Subcubic Graphs&lt;/a&gt;&lt;/em&gt;.
What I describe in this post is based on this first paper. You can find more 
advanced lecture notes on this topic, by Newman, 
&lt;a href=&quot;http://pagesperso.g-scop.grenoble-inp.fr/~newmana/Algorithms2017/ORCO-ConvexCombinationsTSP.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cubic_graph&quot;&gt;Cubic graphs&lt;/a&gt; are graphs in which 
every node has degree 3. These graphs have special structures that are useful 
when designing 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Approximation_algorithm&quot;&gt;approximation algorithms&lt;/a&gt;
for the 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Travelling_salesman_problem&quot;&gt;travelling salesman problem&lt;/a&gt;
(TSP for short), 
and this is the topic of this post.&lt;/p&gt;

&lt;h2 id=&quot;from-tsp-to-graph-tsp-and-then-to-graphical-tsp&quot;&gt;From TSP to Graph-TSP, and then to graphical-TSP&lt;/h2&gt;
&lt;p&gt;First, one may be confused by the fact the TSP is usually defined on weighted
complete graphs, and not on some class of unweighted graphs. Indeed at first it 
does not make sense, as not all the graphs are 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Eulerian_path&quot;&gt;eulerian&lt;/a&gt;, that is, for some graphs 
there does not exist a tour (i.e. a circuit in the graph that visits every 
node exactly once).&lt;/p&gt;

&lt;p&gt;We actually deal with &lt;em&gt;graph-TSP&lt;/em&gt; here, which is TSP on a subset of instances, whose 
edge weights are very special. Graph-TSP on an unweighted graph $G$ with $n$ nodes, 
means that we are looking for 
the shortest tour in the complete graph $C$ on $n$ nodes, where 
the weight of the edge between two arbitrary nodes $u$ and $v$ in $C$, is the length 
of the shortest path  between these nodes in $G$.
This is known as the metric completion of $G$, and 
indeed one can check that these distances follow the triangle inequality.&lt;/p&gt;

&lt;p&gt;Another problem is interesting to us: &lt;em&gt;graphical-TSP&lt;/em&gt;. In this new problem, given 
a graph, one has to find the shortest tour that visits all the nodes, 
but with the relaxation that it can visit the nodes and edges more than 
once.&lt;/p&gt;

&lt;p&gt;“Graph-TSP” and “Graphical-TSP” are unpleasantly close names, but 
fortunately, the problems are equivalent. Suppose you have a tour for 
graph-TSP, then every edge $(u,v)$ has the weight of the path between $u$ and 
$v$ in $G$: one can take this path instead of the direct edge. 
Unfolding every edge this way, one gets a solution for graphical-TSP with the
same weight. A similar construction works for the other 
direction.&lt;/p&gt;

&lt;p&gt;The literature seems to focus on Graph-TSP, probably because it generalizes to 
the classic TSP more easily. For this post, the graphical-TSP is more handy, 
so we continue wih this one.&lt;/p&gt;

&lt;h2 id=&quot;simplified-christofides-algorithm&quot;&gt;Simplified Christofides algorithm&lt;/h2&gt;

&lt;p&gt;Consider the following simple approximation algorithm for graphical-TSP. 
Take a minimum 
spanning tree of the graph $G$, and then consider the path taken if one does a 
traversal of this tree. This is a tour (in the sense of graphical-TSP), 
because every node is visited. It gives 
a 2-approximation, because the optimal tour cannot be lighter than the minimum 
spanning tree, and because every edge is taken exactly twice in this solution.
Also it runs in polynomial-time, and that is what we are looking for.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Christofides_algorithm&quot;&gt;Christofides algorithm&lt;/a&gt; 
is a refinement of this idea, and it gives a 3/2-approximation for metric 
instance of (the general) TSP. In particular it gives a 3/2-approximation 
for graphical-TSP on cubic graphs and we will show how to get better a better 
ratio.&lt;/p&gt;

&lt;h2 id=&quot;a-few-graph-theoretic-definitions&quot;&gt;A few graph theoretic definitions&lt;/h2&gt;
&lt;p&gt;Before we get to why cubic graphs are nice, we need a few definitions from graph theory.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bridge_(graph_theory)#Bridgeless_graphs&quot;&gt;bridge&lt;/a&gt;&lt;/em&gt; 
in a graph, is an edge whose removal disconnects the graph.&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;perfect matching&lt;/em&gt;, is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Matching_(graph_theory)&quot;&gt;matching&lt;/a&gt;, 
i.e. a set of vertex-disjoint edges, that matches all vertices in G.&lt;/li&gt;
  &lt;li&gt;A &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Vertex_cycle_cover&quot;&gt;(vertex disjoint) cycle cover&lt;/a&gt;&lt;/em&gt;
is a set of vertex-disjoint cycles that spans all vertices in G.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the two last definitions are pretty similar, and indeed they are two 
examples of a more general concept, called 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Graph_factorization&quot;&gt;$k$-factors&lt;/a&gt;. But let’s go 
back to cubic graphs.&lt;/p&gt;

&lt;h2 id=&quot;cycle-covers-from-petersens-theorem&quot;&gt;Cycle covers from Petersen’s theorem&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Petersen%27s_theorem&quot;&gt;Petersen’s theorem&lt;/a&gt; states 
that every bridgeless cubic graph, has a perfect matching.&lt;/p&gt;

&lt;p&gt;Now, take a bridgeless cubic graph and remove a perfect matching. What is 
left? A cycle cover of G. 
Indeed the degree of every node has decreased from three to two, thus the 
resulting graph must be union of cycles spanning all nodes.&lt;/p&gt;

&lt;h2 id=&quot;all-together-now&quot;&gt;All together now&lt;/h2&gt;
&lt;p&gt;Let’s put all the ingredients together to get an approximation algorithm for 
graphical-TSP with a better ratio than Christofides algorithm.&lt;/p&gt;

&lt;p&gt;First find a cycle cover of $G$ as in the previous section. This can be
done in poynomial time, thanks to the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Blossom_algorithm&quot;&gt;blossom algorithm&lt;/a&gt;.
This subgraph is visiting 
every node exactly once, but it is not a tour yet, because it is disconnected. 
We will now 
link these cycles together. Consider 
the graph $G’$ made by contracting every cycle into just one node. On this graph 
$G’$, take the tour
induced by the spanning tree as in the simplified Chritofides algorithm. 
This tour corresponds to a set of edges in $G$. 
Now this set of edges plus the edges of the cycle cover form a tour, and we have 
a solution for graphical-TSP!&lt;/p&gt;

&lt;p&gt;What is the weight of this tour? The cycle cover contains exactly $n$ edges. 
Let $c$ be the number of cycles in this cover. Then there are $2c-1$ edges in 
the tree. It follows that the tour has weight $n+2c-1$. With a bit of work&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; one can 
get $c\leq n/6$. This yields to a tour with 
less then $4n/3$ edges. This is a 4/3-approximation, as a tour cannot be shorter 
than $n$, which improves on Christofides.&lt;/p&gt;

&lt;p&gt;We discussed only cubic graphs and got only a small improvement here, 
but the approach based on studying the cycle 
covers is fruitful in other context, and led to many improvements for 
this fundamental problem.&lt;/p&gt;

&lt;h2 id=&quot;bonus-recent-advances-on-asymmetric-tsp&quot;&gt;Bonus: recent advances on asymmetric TSP&lt;/h2&gt;

&lt;p&gt;On a related topic, there has been recent advances on asymmetric TSP, that is 
TSP where the directed edges $(u,v)$ and $(v,u)$ do not have the same weight
in general. 
&lt;a href=&quot;https://arxiv.org/pdf/1708.04215&quot;&gt;A recent paper&lt;/a&gt; gives the  long-awaited
first constant-approximation algorithm for the problem. You will find 
links to a summary and videos on &lt;a href=&quot;http://jakub.tarnawski.org/&quot;&gt;Jakub Tarnawski’s webpage&lt;/a&gt;. 
The paper has been covered on &lt;a href=&quot;https://rjlipton.wordpress.com/2017/09/11/a-tsp-breakthrough/&quot;&gt;Gödel’s lost letter&lt;/a&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, 
and in &lt;a href=&quot;https://www.quantamagazine.org/one-way-salesman-finds-fast-path-home-20171005/&quot;&gt;Quanta magazine&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;To make this work, one needs a stronger version of Petersen’s theorem, to have a better cycle cover. The details are in &lt;a href=&quot;http://dare.ubvu.vu.nl/bitstream/handle/1871/34734/274155.pdf?sequence=1&quot;&gt;this paper&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;A blog by Richard Lipton, that we recently mentioned in our &lt;a href=&quot;https://semidoc.github.io/blogs&quot;&gt;post on TCS blogs&lt;/a&gt; (in French).&amp;nbsp;&lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Mon, 08 Jan 2018 00:00:00 +0100</pubDate>
        <link>https://semidoc.github.io///cubic-TSP</link>
        <guid isPermaLink="true">https://semidoc.github.io///cubic-TSP</guid>
      </item>
    
      <item>
        <title>Communication complexity and information theory</title>
        <description>&lt;p&gt;I attended the annual meeting of the &lt;a href=&quot;https://www.irif.fr/~nschaban/GT-COA/&quot;&gt;complexity and algorithms working 
group of the CNRS&lt;/a&gt; (GT CoA) a few weeks ago, and 
I wanted to review some parts of it. This is the first element of a series of 
posts. The talks at this meeting were quite 
technical, and I cannot give a deep overview of each them. So instead 
I will just write about some details that caught my attention, and that are easy 
to explain, or, like today, give a very succinct	 summary of the story. 
For most of the talks, the post will deal with basic considerations, and 
not with the new things developed by the speakers. 
For comments: feuilloley [at] irif [dot] fr.&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;The first talk was actually a lecture,
entitled &lt;em&gt;Information Theory and Communication Protocols&lt;/em&gt; by Florent Urrutia 
from &lt;a href=&quot;https://www.irif.fr/en/index&quot;&gt;IRIF at Paris Diderot university&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;communication-complexity&quot;&gt;Communication complexity&lt;/h2&gt;

&lt;p&gt;In a nutshell, &lt;a href=&quot;https://en.wikipedia.org/wiki/Communication_complexity&quot;&gt;communication complexity&lt;/a&gt;
measures the number of bits that some agents must exchange to complete a task. 
More precisely, in the basic setting, there are two players, 
traditionally named Alice and Bob, and each of them is given 
half of an input bit string. They both have to output the result of a boolean
function of the (whole) input. A task is for example to output the 
parity of the number of 1s in the input string.
Before outputting, they can communicate, that is exchange some bits one after the other.
Then an easy protocol is to send each other all the (half-)inputs they have, and 
then to compute the output in parallel. The basic question is: for which tasks
you can do better, that is sending less bits than the size of the input?&lt;/p&gt;

&lt;h2 id=&quot;information-complexity&quot;&gt;Information complexity&lt;/h2&gt;
&lt;p&gt;In another nutshell, &lt;a href=&quot;https://en.wikipedia.org/wiki/Information_theory&quot;&gt;information theory&lt;/a&gt; 
measure the amount of information contained in some message given some context. 
This has been 
introduced by Shannon in the forties, and is used in many 
contexts. 
It requires formulas, with logs, sups, infs etc. to 
make this precise, and I do not want to dive into this. If you know about 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Entropy_(information_theory)&quot;&gt;Shannon entropy&lt;/a&gt;, 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Mutual_information&quot;&gt;mutual information&lt;/a&gt; etc., 
you know what I mean. Otherwise, no problem, it is not really
necessary for this post. Now, very roughly speaking, &lt;em&gt;information complexity&lt;/em&gt; measures 
the amount of information that one needs to reveal to solve some task under some 
distribution, and its definition is based on the one of the entropy.&lt;/p&gt;

&lt;h2 id=&quot;information-as-a-lower-bound-on-communication&quot;&gt;Information as a lower bound on communication&lt;/h2&gt;
&lt;p&gt;The focus of the course was to look at the relation between these two fields.
The main point, that is very powerful, can be stated as a naive sentence: the 
number of bits communicated in any protocol to solve the task 
must be larger than the information the players have 
to reveal, in theory, when communicating. Namely, the communication 
complexity must be at least 
the information complexity. As I have not properly defined the two notions, this 
may sound quite useless, I will try to convince the reader that it is interesting. 
What is surprizing is that these two notions are 
quite different in the way they are defined. The first one is defined as a simple 
worst-case measure and has a quite combinatorial flavour, it really counts bits. 
Indeed it is possible 
to prove lower bound on communication complexity by studying some combinatorics 
of 0-1 matrices.&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;
The second one is defined as an infimum (over communication protocols) of a supremum 
over distributions of inputs of an (entropy-like) function that is based on a 
sum of logs. A pretty non-combinatorial object.&lt;/p&gt;

&lt;p&gt;I guess this inequality mainly means that these definitions are the right ones..!&lt;/p&gt;

&lt;h2 id=&quot;further&quot;&gt;Further&lt;/h2&gt;
&lt;p&gt;It is not true that communication complexity is equal to information 
complexity, there can even be an exponential gap between those, but this happens 
in some very special context. See the paper &lt;em&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/fd13/ba5bb068e7887fb450ef6c2cc2a849652db2.pdf&quot;&gt;Exponential Separation of 
Information and
Communication for Boolean Functions&lt;/a&gt;&lt;/em&gt; 
(not for the beginners).&lt;/p&gt;

&lt;p&gt;Nevertheless, this approach is very powerful, and almost all the lower bounds 
we have on 
communication complexity can be phrased as information complexity lower bounds 
(See &lt;a href=&quot;https://arxiv.org/abs/1204.1505&quot;&gt;this paper&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;multi-party-communication-the-more-the-merrier-maybe-not&quot;&gt;Multi-party communication (the more the merrier… maybe not)&lt;/h2&gt;
&lt;p&gt;Multi-party communication is the setting in which the input is split between 
more than two players. In this new setting, lower bounds are 
difficult to get. A natural step is to use information complexity. 
But this is not easy. There are different 
ways to define the information revealed during a multi-party protocol, and none of 
ones we know gives very good bounds.&lt;/p&gt;

&lt;h3 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h3&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;See the classic &lt;em&gt;rectangle method&lt;/em&gt;, for example in &lt;a href=&quot;https://pdfs.semanticscholar.org/6094/392d07d36c086a988493686b73ebca39169b.pdf&quot;&gt;this survey&lt;/a&gt;.&amp;nbsp;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Sat, 23 Dec 2017 00:00:00 +0100</pubDate>
        <link>https://semidoc.github.io///information-communication</link>
        <guid isPermaLink="true">https://semidoc.github.io///information-communication</guid>
      </item>
    
      <item>
        <title>Blogs d'informatique théorique</title>
        <description>&lt;p&gt;Hi everyone, the rest of this post is in French and is basically a list of TCS 
blogs, some in French, some in English.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Bonjour, aujourd’hui un billet sur les blogs d’informatique théorique.  J’ai un 
peu taté le terrain auprès des doctorants de l’&lt;a href=&quot;https://www.irif.fr/index&quot;&gt;IRIF&lt;/a&gt;,
pour savoir ce qui était lu et voilà une partie des résultats, avec de courtes 
descriptions qui n’engagent que moi. Je vous encourage à aller voir vous-même.&lt;/p&gt;

&lt;p&gt;N’hésitez pas à m’envoyer des commentaires et suggestions 
(feuilloley ‘at’ irif ‘point’ fr).&lt;/p&gt;

&lt;h3 id=&quot;the-n-category-cafhttpsgolemphutexaseducategory&quot;&gt;&lt;a href=&quot;https://golem.ph.utexas.edu/category/&quot;&gt;The n-Category Café&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Un blog collectif lu notamment par les catégoriciens. Une dizaines d’auteurs, dont 
&lt;a href=&quot;https://fr.wikipedia.org/wiki/John_Baez&quot;&gt;John Baez&lt;/a&gt; 
(assez présent sur internet, notamment autour de l’open access et du rechauffement 
climatique, et qui a son propre blog, 
&lt;a href=&quot;https://johncarlosbaez.wordpress.com/about/&quot;&gt;Azimut&lt;/a&gt; qui parle de beaucoup 
d’autres choses). Les contenus techniques sont axés catégories, mais avec des 
incursions dans d’autres domaines et des commentaires sur l’informatique en général.&lt;/p&gt;

&lt;h3 id=&quot;shtetl-optimizedhttpswwwscottaaronsoncomblog&quot;&gt;&lt;a href=&quot;https://www.scottaaronson.com/blog/&quot;&gt;Shtetl-Optimized&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Un blog classique en quantique/complexité/nerdisme, par un nerd quantique 
complexe, &lt;a href=&quot;https://fr.wikipedia.org/wiki/Scott_Aaronson&quot;&gt;Scott Aaronson&lt;/a&gt;. 
Des discussions techniques, mais 
surtout le suivi des (non-)avancées des ordinateurs quantiques, une partie de la 
politique américaine 
et des avis sur les trous noirs, la calculabilité, la conscience, et les problèmes d’Uber. 
Entre autres.&lt;/p&gt;

&lt;h3 id=&quot;gagaliumhttpgalliuminriafrblog&quot;&gt;&lt;a href=&quot;http://gallium.inria.fr/blog/&quot;&gt;Gagalium&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Le blog de la communauté &lt;a href=&quot;https://fr.wikipedia.org/wiki/OCaml&quot;&gt;Ocaml&lt;/a&gt;, 
avec du contenu très pointu, mais aussi des 
histoires qui peuvent interesser un plus large public, comme 
&lt;em&gt;&lt;a href=&quot;http://gallium.inria.fr/blog/intel-skylake-bug/&quot;&gt;How I found a bug in Intel Skylake processors&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;windows-on-theoryhttpswindowsontheoryorg&quot;&gt;&lt;a href=&quot;https://windowsontheory.org/&quot;&gt;Windows on Theory&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Blog à &lt;em&gt;n&lt;/em&gt; mains, avec &lt;em&gt;n&lt;/em&gt; grand, mais dont l’auteur principal est aujourd’hui 
&lt;a href=&quot;http://www.boazbarak.org/&quot;&gt;Boak Barak&lt;/a&gt;. Il y est question de &lt;em&gt;theoretical 
computer science&lt;/em&gt; (TCS), selon la compréhension américaine du terme : algorithmes, 
complexité, crypto. Beaucoup de contenus semi-techniques et de discussions sur la 
communauté, les conférences, l’enseignement, les nouveaux domaines, les postes.&lt;/p&gt;

&lt;h3 id=&quot;la-vie-est-mal-configurehttpdavidmonniauxfreefrdotclearindexphp&quot;&gt;&lt;a href=&quot;http://david.monniaux.free.fr/dotclear/index.php/&quot;&gt;La vie est mal configurée&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Le blog de &lt;a href=&quot;http://www-verimag.imag.fr/~monniaux/&quot;&gt;David Monniaux&lt;/a&gt;, prof au CNRS 
à Grenoble. Le plus souvent en français, avec un focus sur l’informatique en 
France (son enseignement, son image dans les médias etc.), sur la recherche en 
informatique en générale (processus de publication, vie de chercheur), et 
parfois de la vulgarisation de contenu technique.&lt;/p&gt;

&lt;h3 id=&quot;gdels-lost-letter-and-pnphttpsrjliptonwordpresscom&quot;&gt;&lt;a href=&quot;https://rjlipton.wordpress.com/&quot;&gt;Gödel’s lost letter and P=NP&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Un autre blog de TCS à l’américaine, généraliste mais avec parfois des billets 
de vulgarisation de sujets vraiment techniques, avec souvent un nouveau point de vue, 
des questions ouvertes, des avis personels etc.. Par 
&lt;a href=&quot;https://fr.wikipedia.org/wiki/Richard_J._Lipton&quot;&gt;Richard Lipton&lt;/a&gt; et Ken Regan.&lt;/p&gt;

&lt;h3 id=&quot;lambda-the-ultimatehttplambda-the-ultimateorg&quot;&gt;&lt;a href=&quot;http://lambda-the-ultimate.org/&quot;&gt;Lambda the ultimate&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Entre le blog et le forum. Contenus techniques sur la théorie des langages de 
	programmation.&lt;/p&gt;

&lt;h3 id=&quot;computational-complexityhttpblogcomputationalcomplexityorg&quot;&gt;&lt;a href=&quot;http://blog.computationalcomplexity.org/&quot;&gt;Computational complexity&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Et pour finir encore un blog dans le domaine algo/complexité, avec aussi des 
énigmes, des annonces de postes, des avis sur les technologies en général. 
Par &lt;a href=&quot;https://en.wikipedia.org/wiki/Lance_Fortnow&quot;&gt;Lance Fortnow&lt;/a&gt; et 
&lt;a href=&quot;https://en.wikipedia.org/wiki/William_Gasarch&quot;&gt;Bill Gasarch&lt;/a&gt;. En passant les blogs de ce type sont regroupés dans le 
&lt;a href=&quot;http://www.feedworld.net/toc/&quot;&gt;Theory of Computing Blog Aggregator&lt;/a&gt;, avec les 
sections &lt;a href=&quot;https://fr.wikipedia.org/wiki/ArXiv&quot;&gt;ArXiv&lt;/a&gt; pertinentes.&lt;/p&gt;

&lt;h3 id=&quot;et-encore-quelques-uns&quot;&gt;Et encore quelques uns&lt;/h3&gt;
&lt;p&gt;Deux blogs de groupes de thésards basés aux États-Unis : 
&lt;a href=&quot;https://mittheory.wordpress.com/&quot;&gt;Not so Great Ideas in Theoretical Computer Science&lt;/a&gt;
et &lt;a href=&quot;http://learningwitherrors.org/&quot;&gt;Learning With Errors&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;On finit avec des blogs de doctorants présents ou passés de l’IRIF :
&lt;a href=&quot;https://drup.github.io/&quot;&gt;Drup&lt;/a&gt; 
de Gabriel Radanne, &lt;a href=&quot;https://fiv0.github.io/&quot;&gt;FiV0&lt;/a&gt; de Finn Völkel
(sur lequel la structure de semidoc est basée),
et les blogs de &lt;a href=&quot;https://luongo.pro/&quot;&gt;Alessandro Luongo&lt;/a&gt;
et de &lt;a href=&quot;https://www.theozimmermann.net/en/blog/&quot;&gt;Théo Zimmermann&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Nov 2017 00:00:00 +0100</pubDate>
        <link>https://semidoc.github.io///blogs</link>
        <guid isPermaLink="true">https://semidoc.github.io///blogs</guid>
      </item>
    
      <item>
        <title>Introduction ludique à la sémantique des jeux</title>
        <description>&lt;p&gt;Hi! This post by Clément Jacq is about &lt;em&gt;game semantics&lt;/em&gt;. It is in 
French but you can check out the slides in English 
&lt;a href=&quot;https://www.irif.fr/~feuilloley/autre/slides_Jacq_seminaire_thesards.pdf&quot;&gt;here&lt;/a&gt;, 
and a more in-depth survey 
&lt;a href=&quot;https://www.dpmms.cam.ac.uk/~martin/Research/Pub91-00/gamesemantics97scan.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Bonjour à tous pour ce premier vrai post en français sur semidoc. Et c’est 
Clément Jacq (ancien responsable du séminaire) qui nous parle 
de &lt;em&gt;sémantique des jeux&lt;/em&gt;, inspiré de son exposé du printemps. Vous pouvez retrouver le 
support de l’exposé 
&lt;a href=&quot;https://www.irif.fr/~feuilloley/autre/slides_Jacq_seminaire_thesards.pdf&quot;&gt;ici&lt;/a&gt; 
et un texte plus approfondi 
&lt;a href=&quot;https://www.dpmms.cam.ac.uk/~martin/Research/Pub91-00/gamesemantics97scan.pdf&quot;&gt;là&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;smantique-des-jeux-antique&quot;&gt;Sémantique des jeux antique&lt;/h1&gt;
&lt;p&gt;La sémantique des jeux a d’abord été introduite dans les années 50 par 
Lorenzen and Lorenz. L’objectif était de lier les notions de vérité et 
de validité de la &lt;a href=&quot;https://fr.wikipedia.org/wiki/Logique_classique&quot;&gt;logique classique&lt;/a&gt; 
à des concepts de &lt;a href=&quot;https://fr.wikipedia.org/wiki/Th%C3%A9orie_des_jeux&quot;&gt;théorie des jeux&lt;/a&gt; 
telles que l’existence de stratégie. L’intuition est la suivante . 
Pour chaque formule, on construit un jeu d’arêne à deux joueurs :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Les deux joueurs sont le Vérificateur et le Falsificateur.&lt;/li&gt;
  &lt;li&gt;chaque connecteur et chaque constante de la formule sont des positions 
du jeu “contrôlées” par l’un des deux joueurs.&lt;/li&gt;
  &lt;li&gt;Lorsque le jeu est dans une position qu’un joueur contrôle, celui-ci 
peut choisir la position suivante parmi les positions disponibles.&lt;/li&gt;
  &lt;li&gt;La partie se termine quand il n’y a pas de choix pour le joueur en 
cours, celui-ci est alors désigné vainqueur.&lt;/li&gt;
  &lt;li&gt;La formule est vraie si et seulement si il existe une stratégie 
gagnante pour le Vérificateur. C’est à dire que quelque soient les choix 
du Falsificateur, le Vérificateur peut toujours orienter la partie vers 
une position finale sous son contrôle.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Voici un exemple du jeu associé à la formule de logique propositionnelle 
$(V \cup F) \wedge \neg (F \cup V)$&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/AntiqueGame3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Les atomes Vrai et $\cup$ sont associés au Vérificateur (en bleu) et les 
atomes Faux et $\wedge$ au Falsificateur (en rouge). A noter le role 
particulier de la négation qui inverse les possesseurs des positions de 
son sous-arbre.  La formule est ici fausse car le falsificateur peut 
jouer dans la branche de droite sans laisser au Vérificateur une 
possibilité d’influer sur les positions.&lt;/p&gt;

&lt;h1 id=&quot;des-stratgies-et-des-jeux&quot;&gt;Des stratégies et des jeux&lt;/h1&gt;
&lt;p&gt;On va s’intêressé ici à une sémantique des jeux plus moderne créée à la 
suite des travaux de &lt;a href=&quot;https://fr.wikipedia.org/wiki/Jean-Yves_Girard&quot;&gt;Girard&lt;/a&gt; 
sur la &lt;a href=&quot;https://fr.wikipedia.org/wiki/Logique_lin%C3%A9aire&quot;&gt;logique linéaire&lt;/a&gt; 
en 1987. De nombreux 
travaux dans ce domaine sont apparus dans manière simultanée dans les 
années 90. Citons notamment ceux d’Abramsky, de Blass, de Hyland ou de 
Ong.  Une des particularités de la logique linéaire est qu’elle permet 
de bien retranscrire le fonctionnement d’un programme. Pour simplifier
 cette présentation, nous modéliserons directement par nos jeux un 
 langage de programmation simple.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Définition&lt;/strong&gt;
Un jeu simple est un jeu d’arbre enraciné à deux joueurs, que l’on 
appelera Opposant et Joueur, qui joue chacun leur tour et dont les 
parties sont de taille finie. De plus nous ajoutons la règle que 
l’Opposant est toujours le premier à jouer.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/ExampleGame2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici un exemple de jeu simple, les noeuds sont appelés des positions et 
les arêtes des coups. Les positions bleues sont celles où l’Opposant 
s’apprête à choisir un coup.&lt;/p&gt;

&lt;p&gt;Avec cette notion de jeu, nous avons besoin d’une notion de stratégie. 
Par usage, on se place du point de vue de Joueur, c’est à dire qu’une 
stratégie est un ensemble indiquant à Joueur comment jouer. Plus 
formellement:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Définition&lt;/strong&gt;
Une stratégie pour Joueur d’un jeu G est un ensemble de parties de $G$ 
clos par préfixe ( c’est à dire que la stratégie ne contient des 
informations que sur les parties qu’on peut atteindre par celle-ci), et 
déterministe ( à chaque position, Joueur n’a au plus qu’un seul choix 
qui est dans la stratégie)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/ExampleStrat.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voici un exemple de stratégie pour le jeu montré précédemment. On peut 
noter qu’il s’agit d’un sous-arbre du jeu en question.&lt;/p&gt;

&lt;p&gt;Ceci nous donne les bases pour construire nos premiers programmes .&lt;/p&gt;

&lt;h1 id=&quot;modliser-de-simples-programmes&quot;&gt;Modéliser de simples programmes&lt;/h1&gt;
&lt;p&gt;Le langage de programmation que nous allons modéliser par nos jeux est 
un language fonctionnel typé (par exemple &lt;a href=&quot;https://fr.wikipedia.org/wiki/Caml&quot;&gt;Caml&lt;/a&gt;).
L’idée générale est la suivante :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Chaque type du langage correspond à un jeu. (On peut donc imaginer 
un jeu Bool, un jeu Int,…)&lt;/li&gt;
  &lt;li&gt;Chaque programme valide de type A correspond à une stratégie du 
jeu $A$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Une bonne intuition à noter pour la suite est que les rôles des deux 
joueurs du jeu peuvent représenter l’Environnement et le Programme dans 
l’interaction. C’est pour cela qu’on peut voir un programme valide comme 
une stratégie pour Joueur, car une stratégie indique alors les 
comportements raisonnables du Programme face à l’Environnement.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;assets/BoolGame.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;assets/IntGame.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Voici deux exemples deux jeux, réprésentant les types simples que sont 
les booléens et les entiers. Une stratégie dans un de ces types 
représente tout simplement une constante, l’unique moment ou Joueur doit 
faire un choix étant le choix de la valeur. Par exemple, voici la 
stratégie associée à la constante Vrai :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/BoolStratTrue.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Maintenant que nous avons mis en place les types simples de constante, 
mettons en place des types un peu plus complexe. Commençons par les 
paires (et plus généralement les n-uplets). L’intuition est extrèmement 
simple. Pour construire le type des paires de deux booléens, on prend 
le jeu Bool en double et on peut jouer dans les deux instances au choix, 
obtenant au final une paire de booléens.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/TensBoolGame1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Il est bon de noter que cela ne forme pas un jeu au sens où nous l’avons 
défini. En effet, il n’y a pas une unique racine et l’ordre des coups 
entre les deux jeux n’est pas clair. La définition formelle du jeu$Bool 
\otimes Bool$ est un peu plus complexe :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/TensBoolGame2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;introduction-des-fonctions&quot;&gt;Introduction des fonctions&lt;/h2&gt;
&lt;p&gt;Jusqu’à présent, tous les programmes que nous avons décrits sont 
quasiment triviaux. il ne s’agissait que de constantes. En terme 
d’interaction, ces programmes se comportent de la manière suivante : 
Opposant/l’Environnement demande des valeurs spécifiques et Joueur/le 
Programme les lui fournit.\&lt;/p&gt;

&lt;p&gt;Pour les fonctions, l’interaction inverse va aussi avoir lieur. Le 
Programme va demander des arguments qui vont être fournis par 
l’Environnement. Intuitivement, en se souvenant du rôle de la négation 
en sémantique des jeux historique, le jeu de type $A\rightarrow B$ peut 
etre vu comme $(\neg A) \otimes B$. Prenons l’exemple du jeu 
$Bool \rightarrow Bool$ :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/ArrowBoolGame1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Comme indiqué par l’intuition, la partie gauche du jeu, qui correspond à 
l’argument est inversée. Pour clarifier un peu le dessin, ajoutons en 
pointillé les endroits ou l’on peut passer d’un jeu à l’autre tout en 
respectant les règles d’alternance des jeux simples :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/ArrowBoolGame2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Ce jeu donne bien l’intuition des fonctions booléennes possibles. Une 
fois que l’environnement a demandé le résultat, le joueur peut soit 
répondre immédiatement ( fonction constante), soit demander un argument 
avant de répondre.
Voici par exemple la stratégie correspondant à la  Negation booléenne :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/ArrowBoolStrat5.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Comme dans le cas des paires, le véritable jeu est une construction plus 
complexe&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/ArrowBoolGame3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;En conclusion de cette partie, voici une partie de la stratégie associée 
au OR booleen dans une représentation plus légère indiquant les coups 
joués dans l’ordre et dans le sous-jeu dans lequel ils sont joués :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ccccc}
 \mathbb{B} &amp; \otimes &amp; \mathbb{B} &amp; \rightarrow &amp; \mathbb{B} \\
 	&amp;	     &amp;	      &amp;		       &amp;    q     \\
     q     &amp;	     &amp;	      &amp;		       &amp;        \\
     F     &amp;	     &amp;	      &amp;		       &amp;         \\
 	&amp;	     &amp;	 q    &amp;		       &amp;         \\
 	&amp;	     &amp;	 V   &amp;		       &amp;         \\
 	&amp;	     &amp;	      &amp;		       &amp;    V     \\
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Il est important de noter que cette partie ne correspond qu’a une 
version possible du programme OR. En effet, un choix a lieu lors de 
l’implémentation d’un OR; le choix du premier argument à étudier. Il y a 
donc plusieurs programmes pour le OR et donc plusieurs stratégies.&lt;/p&gt;

&lt;h1 id=&quot;stratgie-de-composition-pour-la-composition-de-stratgies&quot;&gt;Stratégie de composition pour la composition de stratégies&lt;/h1&gt;
&lt;p&gt;Puisqu’il est possible et même fort utile de composer des fonctions, 
notre modèle doit pouvoir composer les stratégies de manière facile. 
Cette composition se construit en parcourant toutes les paires de 
parties des deux stratégies, (c’est à dire tous les cas possibles des 
deux fonctions).&lt;/p&gt;

&lt;p&gt;Prenons une partie d’une stratégie $\sigma :A \rightarrow B$ et une 
 partie d’une stratégie $\tau : B \rightarrow C$ telles que leurs 
 composantes en $B$ sont égales. Intuivement, cela revient à s’intéresser 
 au cas où l’argument de $\tau $ correspond au resultat de $\sigma$. 
 L’idée est alors de réorganiser les deux parties en fonction de leur 
 composante commune, avant d’effacer celle-ci. La représentation 
 graphique montre ce processus.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/Composition1.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;
&lt;img src=&quot;assets/Composition2.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;
&lt;img src=&quot;assets/Composition3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Cette méthode de composition est aussi la manière dont est représentée 
l’application d’une fonction à un argument, l’argument étant vu comme 
une stratégie constante de son type.&lt;/p&gt;

&lt;h1 id=&quot;pour-quelques-blocs-de-plus&quot;&gt;Pour quelques blocs de plus&lt;/h1&gt;
&lt;p&gt;## Test
Maintenant que nous avons les bases d’un bon langage fonctionnel, 
ajoutons quelques structures de controle. Commençons par la plus simple, 
le test. L’intuition pour cette fonction est très simple. Elle nécessite 
trois arguments, dont un booleen qui représentera le test proprement 
dit. La fonction commence par demander la valeur de ce booleen. S’il est 
Vrai, alors elle demande puis renvoie la valeur du premier argument 
restant. Sinon, elle demande puis renvoie le second. Voici les 
représentations de deux parties de cette stratégie, dans le cas 
d’arguments entiers :&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ccccccc}
 \mathbb{B} &amp; \otimes &amp; \mathbb{I}&amp; \otimes &amp; \mathbb{I} &amp; \rightarrow &amp; \mathbb{I} \\
 	&amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;    q    \\
     q     &amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;         \\
     F     &amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;         \\
 	&amp;	     &amp;	      &amp;	&amp; q  &amp;	       &amp;         \\
 	&amp;	     &amp;	    &amp;	&amp;  n' &amp; 	       &amp;         \\
 	&amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;    n'     \\
\end{array} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ccccccc}
 \mathbb{B} &amp; \otimes &amp; \mathbb{I}&amp; \otimes &amp; \mathbb{I} &amp; \rightarrow &amp; \mathbb{I} \\
 	&amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;    q     \\
     q     &amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;         \\
     V     &amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;         \\
 	&amp;	     &amp;	  q    &amp;	&amp; &amp;	       &amp;         \\
 	&amp;	     &amp;	  n   &amp;	&amp;   &amp; 	       &amp;         \\
 	&amp;	     &amp;	      &amp;	&amp;  &amp;	       &amp;    n     \\
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;A noter que puisque notre langage est typé, c’est aussi le cas du test.&lt;/p&gt;

&lt;p&gt;Il existe donc toute une gamme de fonctions de test, une par type.&lt;/p&gt;

&lt;h2 id=&quot;boucle&quot;&gt;Boucle&lt;/h2&gt;
&lt;p&gt;Pour terminer, nous nous interesserons à la modélisation des boucles. 
Pour ce faire, nous devons introduire deux nouvelles structures, le 
$!$ et le $?$. Pour un jeu $A$, $!A$ est le jeu basé sur $A$ dans lequel 
l’Opposant est autorisé à revenir en arrière et à rejouer des coups 
( forçant Joueur à y répondre). $?A$ fonctionne de la même manière, mais 
pour Joueur.&lt;/p&gt;

&lt;p&gt;Dans une stratégie quelconque d’un tel jeu, Joueur, si il se retrouve 
plusieurs fois devant le même choix (par répétition de mouvements 
d’Opposant), peut répondre de manière différente à chaque fois. Cela ne 
contredit pas le déterminisme, car on s’intéresse ici au déterminisme 
dans l’arbre correspondant à $!A$ qui est beaucoup plus complexe que 
celui de $A$. Si la $même$ position est jouée deux fois par Opposant, 
il y aura deux noeuds distincts dans l’arbre de $!A$.&lt;/p&gt;

&lt;p&gt;Pour se rendre compte de ce qu’il est effectivement possible de faire, 
voici un exemple de partie de $!(Bool \rightarrow Bool)$.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ccccc}
 \mathbb{B} &amp;  \rightarrow &amp; \mathbb{B} \\
 	&amp;	    	       &amp;    q     \\
     q     &amp;	    	       &amp;         \\
     F     &amp;	    	       &amp;         \\
 	&amp;	    	       &amp;    V     \\
    V     &amp;	    	       &amp;        \\
 	&amp;	    	       &amp;    F    \\
     F     &amp;	    	       &amp;    q    \\
    q	&amp;	    	       &amp;        \\
     F     &amp;	    	       &amp;        \\
 	&amp;	    	       &amp;    F     \\
\end{array} %]]&gt;&lt;/script&gt;

&lt;p&gt;Dans le cas de la boucle whle, le jeu associé va utiliser à la fois $!$ 
sur la partie gauche de la fonction et $?$ sur la partie droite. C’est 
donc joueur qui sera au contrôle des retours en arrière.&lt;/p&gt;

&lt;p&gt;La fonction sera de type &lt;script type=&quot;math/tex&quot;&gt;! \mathbb{B}  \rightarrow ? A&lt;/script&gt; et 
fonctionne de la manière suivante. Joueur commence par demander la 
valeur du test booleen, s’il est vrai, les calculs reprennent dans $A$ 
jusqu’à ce que joueur considère qu’il doit demander de nouveau un test, 
ce qui le fera recommencer les calculs si ce nouveau test est vrai. Et 
ainsi de suite jusqu’à ce qu’un test retourne faux. En ce cas, Joueur 
conclue la partie en renvoyant le résultat.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{array}{ccccc}
 !\mathbb{B} &amp;  \rightarrow &amp; ? A \\
 	&amp;	    	       &amp;    q     \\
     q     &amp;	    	       &amp;         \\
     V     &amp;	    	       &amp;         \\
 	&amp;	  	       &amp;   ....       \\
    q     &amp;	    	       &amp;         \\
    V	&amp;	    	       &amp;        \\
          &amp;	    	       &amp;    ...    \\
    q	&amp;	    	       &amp;         \\
     F     &amp;	    	       &amp;         \\
 	&amp;	    	       &amp;    res     \\
\end{array} %]]&gt;&lt;/script&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Cette présentation n’a abordé que quelques aspects de base de la 
modélisation des langages de programmation en sémantique des jeux et ne 
s’est appuyé que sur un modèle particulier. Bien d’autres modèles de 
jeux existent pouvant modéliser bien d’autres comportements, tels que 
le non-déterminisme, la concurrence, les Effets, les Références ou les 
Langages Objets. Pour ce dernier exemple, un langage de programmation 
orienté Objet, Eriskay a été developpé par Jon Longley en se basant sur 
les concepts de la sémantique des jeux.&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Sep 2017 00:00:00 +0200</pubDate>
        <link>https://semidoc.github.io///jacq-jeux</link>
        <guid isPermaLink="true">https://semidoc.github.io///jacq-jeux</guid>
      </item>
    
      <item>
        <title>One-bit catastrophe</title>
        <description>&lt;p&gt;Hi! Today &lt;a href=&quot;https://www.irif.fr/~glagarde/&quot;&gt;Guillaume Lagarde&lt;/a&gt; 
gives an overview of the recent preprint he has with
his advisor &lt;a href=&quot;https://www.irif.fr/~sperifel/&quot;&gt;Sylvain Perifel&lt;/a&gt;: 
&lt;a href=&quot;https://arxiv.org/abs/1707.04312&quot;&gt;Lempel-Ziv: a “one-bit catastrophe” but not a tragedy&lt;/a&gt;.
He presented parts of it at the PhD seminar last spring.&lt;/p&gt;

&lt;h2 id=&quot;a-strange-scenario&quot;&gt;A strange scenario&lt;/h2&gt;

&lt;p&gt;Imagine you compressed a file using your favorite compression
algorithm, but you realize that there was a typo in the file. 
You then correct it, adding a single bit to the original file.&lt;/p&gt;

&lt;p&gt;Compress it again and you get a much
larger compressed file… for just a one-bit difference! Much
compression algorithms do not have this strange behavior, but for
LZ’78, one of the most famous of them, this surprising scenario might
well happen. This is what we will overview in this post.&lt;/p&gt;

&lt;h2 id=&quot;introduction-to-lz78-and-notations&quot;&gt;Introduction to LZ’78 and notations&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/LZ77_and_LZ78&quot;&gt;Lempel-Ziv (LZ in short)
algorithms&lt;/a&gt; refer to a
bunch of lossless compression techniques introduced by &lt;a href=&quot;https://en.wikipedia.org/wiki/Abraham_Lempel&quot;&gt;Abraham
Lempel&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Jacob_Ziv&quot;&gt;Jacob
Ziv&lt;/a&gt; that are used as key
ingredients in various places such as
&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/DEFLATE&quot;&gt;deflate&lt;/a&gt;&lt;/em&gt;,
&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/GIF&quot;&gt;gif&lt;/a&gt;&lt;/em&gt;,
&lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gzip&quot;&gt;gzip&lt;/a&gt;&lt;/em&gt;, etc.  The version we
consider is LZ’78, and works by cutting the word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; we want to
compress into substrings, called blocks, &lt;script type=&quot;math/tex&quot;&gt;w = m_1m_2\dots m_k&lt;/script&gt;,
such that each block &lt;script type=&quot;math/tex&quot;&gt;m_i&lt;/script&gt;, except maybe the last one, is a maximal
extension of a previous block, that is: &lt;script type=&quot;math/tex&quot;&gt;m_i = m_j.a&lt;/script&gt; for some
letter &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;m_i&lt;/script&gt; is not equal to &lt;script type=&quot;math/tex&quot;&gt;m_l&lt;/script&gt;, for &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
l &lt; i %]]&gt;&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;For example, consider the word &lt;script type=&quot;math/tex&quot;&gt;w = 00010110100001&lt;/script&gt;. The first
block is always the first letter (it is the extension of the empty
word &lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt;), so that &lt;script type=&quot;math/tex&quot;&gt;m_1 = 0&lt;/script&gt;. Then, &lt;script type=&quot;math/tex&quot;&gt;m_2 = 00&lt;/script&gt;, since
this is the smallest prefix of &lt;script type=&quot;math/tex&quot;&gt;0010110100001&lt;/script&gt; which is not equal to
a word in the set &lt;script type=&quot;math/tex&quot;&gt;\{\epsilon,0\}&lt;/script&gt;. Then, &lt;script type=&quot;math/tex&quot;&gt;m_3 = 1&lt;/script&gt; since this is
the smallest prefix of &lt;script type=&quot;math/tex&quot;&gt;10110100001&lt;/script&gt; which is not equal to a word in
&lt;script type=&quot;math/tex&quot;&gt;\{\epsilon,0,00\}&lt;/script&gt;, and so on. In the end, &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; is cut as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0|00|1|01|10|100|001&lt;/script&gt;

&lt;p&gt;It is not hard to see that there is a unique cut that satisfies this
property. Then, the compression algorithm LZ’78 encodes each block
&lt;script type=&quot;math/tex&quot;&gt;m_i&lt;/script&gt; as a couple &lt;script type=&quot;math/tex&quot;&gt;(p_i,a_i)&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;p_i&lt;/script&gt; is a &lt;em&gt;pointer&lt;/em&gt; to its
&lt;em&gt;predecessor&lt;/em&gt; &lt;script type=&quot;math/tex&quot;&gt;m_j&lt;/script&gt; together with the letter &lt;script type=&quot;math/tex&quot;&gt;a_i&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;m_i
= m_j.a_i&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The previous word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; is thus encoded as&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;(\epsilon,0);(0,0);(\epsilon,1);(0,1);(2,0);(4,0);(1,1)&lt;/script&gt;

&lt;p&gt;The compression size is the number of bits needed to represent the
compressed version of the word and is equal to &lt;script type=&quot;math/tex&quot;&gt;\Theta(\sum_{i=1}^k
(|p_i| + 1))&lt;/script&gt;. In fact, it can be shown that the order of the
compression size is &lt;script type=&quot;math/tex&quot;&gt;\Theta(k\log k)&lt;/script&gt; where &lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; is the number of
blocks; this shows that the important and unique parameter needed is
&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;, the number of blocks. The &lt;em&gt;dictionnary&lt;/em&gt; of a word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;,
written &lt;script type=&quot;math/tex&quot;&gt;D(w)&lt;/script&gt; will be the set of all the blocks &lt;script type=&quot;math/tex&quot;&gt;m_i&lt;/script&gt;. With this
notation in hand, the size of the compression can be rephrased as
&lt;script type=&quot;math/tex&quot;&gt;\Theta(|D(w)| \log |D(w)|)&lt;/script&gt;. A word is said to be &lt;em&gt;incompressible&lt;/em&gt;
if the size of the compression is of the order of the size of the
word. Equivalently, a word is incompressible if &lt;script type=&quot;math/tex&quot;&gt;|D(w)|=
\Theta\left(\frac{|w|}{\log |w|}\right)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The most compressible words are obtained by taking the concatenation
of the prefixes of any word &lt;script type=&quot;math/tex&quot;&gt;x_0.x_1\dots x_{n-1}&lt;/script&gt;. That is, the
most compressible words are of the form &lt;script type=&quot;math/tex&quot;&gt;w
=x_0.(x_0.x_1)(x_0.x_1.x_2)...(x_0.x_1\dots x_{n-2}.x_{n-1})&lt;/script&gt;. The
size of the dictionnary of such word is &lt;script type=&quot;math/tex&quot;&gt;\Theta\left(|w|^{1/2}\right)&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;one-bit-catastrophe-and-results&quot;&gt;One-bit catastrophe and results&lt;/h2&gt;

&lt;p&gt;The &lt;em&gt;one-bit catastrophe question&lt;/em&gt; asks whether there exists a
compressible (infinite) word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;0w&lt;/script&gt; is
incompressible. We answer positively this question by showing our main
theorem:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem 1:&lt;/strong&gt; There exists an infinite word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; such that the
compression ratio changes from &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; to at least &lt;script type=&quot;math/tex&quot;&gt;\frac{1}{6075}&lt;/script&gt; by
adding one single bit in front of &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;In fact, this result is not as tragic as it seems. Indeed, for the
ratio to change, the word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; needs to be compressible, but very
slowly; in symbol &lt;script type=&quot;math/tex&quot;&gt;|D(w)| = \Omega\left(\frac{|w|}{\log^2 |w|}\right)&lt;/script&gt; – this
is quite close to an incompressible word!&lt;/p&gt;

&lt;p&gt;More generally, we can be more precise by considering the possible
variations of the compression size on finite words:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem 2&lt;/strong&gt; For any finite word &lt;script type=&quot;math/tex&quot;&gt;w\in\{0,1\}&lt;/script&gt; and any letter &lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;|D(aw)| \leq 3\sqrt{|w|.|D(w)|}.&lt;/script&gt;

&lt;p&gt;Moreover, we can show that this result is tight up to a multiplicative constant.&lt;/p&gt;

&lt;p&gt;In particular, Theorem 2 tells us that any compressible word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; for
which the size of the dictionnary is &lt;script type=&quot;math/tex&quot;&gt;o\left(\frac{|w|}{\log^2 |w|}\right)&lt;/script&gt;
remains compressible when we add any letter in front of it, i.e
&lt;script type=&quot;math/tex&quot;&gt;|D(aw)| = o\left(\frac{|aw|}{\log |aw|}\right)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Theorem 2 also tells us that for the most compressible words, the
variation can change from &lt;script type=&quot;math/tex&quot;&gt;\Theta \left(|w|^{1/2}\right)&lt;/script&gt; to
&lt;script type=&quot;math/tex&quot;&gt;\Theta \left(|w|^{3/4}\right)&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;high-level-ideas-of-the-proofs&quot;&gt;High level ideas of the proofs&lt;/h2&gt;

&lt;p&gt;The first step is to understand how to get a &lt;em&gt;weak&lt;/em&gt; catastrophe, that
is a word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; such that &lt;script type=&quot;math/tex&quot;&gt;|D(w)| = \Theta\left(|w|^{1/2}\right)&lt;/script&gt; and &lt;script type=&quot;math/tex&quot;&gt;|D(0w)|
= \Theta\left(|0w|^{3/4}\right)&lt;/script&gt;. For that, we consider a word &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; which is
the concatenation of the prefixes of a word &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;, where &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; has a
maximal number of different substrings: &lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is a 
&lt;a href=&quot;https://en.wikipedia.org/wiki/De_Bruijn_sequence&quot;&gt;de Bruijn word&lt;/a&gt;;
this alone should be sufficient to get a weak catastrophe (simulations
say!), but we were not able to prove it directly. Instead, we need to
add in an adaptative way small words between the prefixes, called
gadgets, in order to have more control on the parsing of &lt;script type=&quot;math/tex&quot;&gt;w&lt;/script&gt; and
&lt;script type=&quot;math/tex&quot;&gt;0w&lt;/script&gt; simultaneously.&lt;/p&gt;

&lt;p&gt;With this &lt;em&gt;weak&lt;/em&gt; catastrophe in hand, the idea is now to create the
&lt;em&gt;true catastrophe&lt;/em&gt; (from compressible to incompressible word). We do
that by creating probabilistically a lot of “independent de
Bruijn-style words” which will be used to create a lot of independent
weak catastrophes at the same time. Then by tuning some parameters
like the size or the number of weak catastrophes, together coupled
with new and independent gadgets between the words, we get a
catastrophe.&lt;/p&gt;

&lt;h2 id=&quot;open-questions&quot;&gt;Open questions&lt;/h2&gt;

&lt;p&gt;Is it possible to push the limits as far as to get a catastrophe where the
compression ratio changes from &lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; to &lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;? This would yield as the
worst possible configuration.&lt;/p&gt;

&lt;p&gt;The main challenge, to our mind, is to remove the gadgets in our
constructions. This would mean that the &lt;em&gt;weak catastrophe&lt;/em&gt; is the
typical case for optimally compressible words.&lt;/p&gt;
</description>
        <pubDate>Mon, 11 Sep 2017 00:00:00 +0200</pubDate>
        <link>https://semidoc.github.io///lagarde-catastrophe</link>
        <guid isPermaLink="true">https://semidoc.github.io///lagarde-catastrophe</guid>
      </item>
    
      <item>
        <title>Sturmian words</title>
        <description>&lt;p&gt;Hi, this is the second post by &lt;a href=&quot;https://www.irif.fr/users/rotondo/index&quot;&gt;Pablo Rotondo&lt;/a&gt;.
This one is about sturmian words, and sometimes refers to the first post about 
continued fractions, that you can found &lt;a href=&quot;https://semidoc.github.io/rotondo-fractions&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Sturmian words are infinite words ${\bf{u}}=u_0u_1\ldots\in \mathcal{A}^\infty$ 
(sequences of symbols $u_i$ from an alphabet $\mathcal{A}$) that have numerous 
characterizations, as the coding of digital lines, as rotation sequences, minimal 
complexity sequences…&lt;/p&gt;

&lt;h3 id=&quot;a-first-definition&quot;&gt;A first definition&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Definition&lt;/em&gt; [Sturmian word]
Consider $\alpha,\beta \in [0,1)$ with $\alpha$ irrational. We define infinite words
&lt;script type=&quot;math/tex&quot;&gt;\left(\underline{s}_{\alpha,\beta}(n)\right)_{n\in\mathbb{N}}&lt;/script&gt; 
and 
&lt;script type=&quot;math/tex&quot;&gt;\left(\bar{s}_{\alpha,\beta}(n)\right)_{n\in\mathbb{N}}&lt;/script&gt; 
by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\underline{s}_{\alpha,\beta}(n)= \left\lfloor (n+1)\,\alpha +\beta \right\rfloor - \left\lfloor n\,\alpha +\beta \right\rfloor\, ,&lt;/script&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{s}_{\alpha,\beta}(n)= \left\lceil (n+1)\,\alpha +\beta \right\rceil - \left\lceil n\,\alpha +\beta \right\rceil\,,&lt;/script&gt;

&lt;p&gt;for each $n\in \mathbb{N}$. A binary word ${\bf{u}} \in {0,1}^\infty$ is 
Sturmian if and only if it is of the form 
&lt;script type=&quot;math/tex&quot;&gt;u_n = \underline{s}_{\alpha,\beta}(n),\,\forall n&lt;/script&gt;,
or 
&lt;script type=&quot;math/tex&quot;&gt;u_n = \bar{s}_{\alpha,\beta}(n),\,\forall n&lt;/script&gt; 
for some $\alpha,\beta$ as above. The irrational number $\alpha$ is called the 
&lt;em&gt;slope&lt;/em&gt; of the word $\bf{u}$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt; Observe that if ${\bf{u}}=\underline{s}_{\alpha,\beta}$&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{n\to\infty} \frac{|u_0\ldots u_{n-1}|_1}{n} = \lim_{n\to\infty} \frac{1}{n}\,\sum_{i=0}^{n-1}u_i = \lim_{n\to\infty} \frac{\left\lfloor n\,\alpha +\beta \right\rfloor-\left\lfloor \beta \right\rfloor}{n} = \alpha\,,&lt;/script&gt;

&lt;p&gt;where 
&lt;script type=&quot;math/tex&quot;&gt;|\cdot|_1&lt;/script&gt;
denotes the number of ones in the word. Thus $\alpha$ represents the &lt;em&gt;frequency&lt;/em&gt; 
of ones. Clearly the same result is true when 
&lt;script type=&quot;math/tex&quot;&gt;{\bf{u}}=\bar{s}_{\alpha,\beta}&lt;/script&gt; 
by the same argument.&lt;/p&gt;

&lt;h3 id=&quot;sturmian-words-as-circle-rotations&quot;&gt;Sturmian words as circle rotations&lt;/h3&gt;
&lt;p&gt;The above definition can be seen more intuitively as the binary coding of the 
trajectory of a point on a circle of circumference $1$. This circle is realized 
as the interval $[0,1]$ identifying $0$ and $1$, that is, taking fractional 
parts $x\mapsto {x}$ or, equivalently, modulo one $x\mapsto x \bmod 1$.&lt;/p&gt;

&lt;p&gt;Indeed, observe that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\bar{s}_{\alpha,\beta}(n)=   1 \Longleftrightarrow n\alpha + \beta \leq m &lt; (n+1)\alpha + \beta %]]&gt;&lt;/script&gt;

&lt;p&gt;for some integer $m$. By taking $\bmod 1$ it is immediately seen that this means 
that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{s}_{\alpha,\beta}(n)  = 1 \Longleftrightarrow \{n\alpha + \beta\} \in I_1  := [1-\alpha,1)\,,&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\bar{s}_{\alpha,\beta}(n)  = 0 \Longleftrightarrow \{n\alpha + \beta\} \in I_0  := [0,1-\alpha)\,.&lt;/script&gt;

&lt;p&gt;A similar definition can be done for 
&lt;script type=&quot;math/tex&quot;&gt;\underline{s}_{\alpha,\beta}(n)&lt;/script&gt; 
by reversing the close-open in the border of the intervals. In terms of the 
circle, this reads: start from a point 
&lt;script type=&quot;math/tex&quot;&gt;y_0=\beta&lt;/script&gt; 
on the circle and rotate an arc-length of $\alpha$ on each discrete time 
&lt;script type=&quot;math/tex&quot;&gt;y_{k+1} = (\alpha + y_k)\bmod 1&lt;/script&gt;, 
then code the resulting points by $1$ when they belong to 
&lt;script type=&quot;math/tex&quot;&gt;I_1&lt;/script&gt; 
and 
$0$ when they belong to 
&lt;script type=&quot;math/tex&quot;&gt;I_0&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/rotondo_plot4.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;factors-of-sturmian-words&quot;&gt;Factors of Sturmian words.&lt;/h3&gt;

&lt;p&gt;The finite patterns appearing within our infinite words ${\bf{u}}$ are a 
fundamental object of study in the field of Combinatorics of Words. We say that 
$w\in {0,1}^m$ is a &lt;em&gt;factor&lt;/em&gt; of ${\bf{u}}$ if, for some index $i\geq 0$, we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_1\ldots w_m = u_i \ldots u_{i+m-1}\,,&lt;/script&gt;

&lt;p&gt;and say that $m$ is its &lt;em&gt;length&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We have seen that digits in a Sturmian word ${\bf{u}}$ correspond to intervals 
$I_0$ and $I_1$, this process can be iterated to explain what happens with 
larger factors $w\in {0,1}^m$. The result being that factors are in 
correspondance with the circle intervals delimited by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0,-\alpha,-2\alpha,\ldots,-m\alpha\,,&lt;/script&gt;

&lt;p&gt;modulo $1$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;assets/rotondo_plot3.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; height=&quot;300px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remark&lt;/strong&gt; [Complexity of a Sturmian word]
Since $\alpha$ is irrational, the points&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0,-\alpha,-2\alpha,\ldots,-m\alpha\,,&lt;/script&gt;

&lt;p&gt;modulo $1$ are all distinct.&lt;/p&gt;

&lt;p&gt;Thus the the above points delimit $m+1$ circle intervals: we have $m+1$ factors 
$w\in {0,1}^m$ of length $m$ appearing in $\bf{u}$. This is the smallest 
possible number of factors of length $m$ in the sense that, if we had at most 
$m$ factors of length $m$ for some $m$, our words would be eventually periodic.&lt;/p&gt;

&lt;p&gt;The intervals-factor correspondence is independent from $\beta$. In particular, 
the set of factors of length $m$ appearing within ${\bf{u}}$ depends only on the 
choice of $\alpha$. Furthermore, the sequence ${n\alpha}$ is &lt;em&gt;equidistributed&lt;/em&gt; 
(also known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Equidistributed_sequence&quot;&gt;uniform distribution $\bmod. 1$&lt;/a&gt;) 
meaning that the proportion of the time it spends on an interval $I$ tends to 
its length 
&lt;script type=&quot;math/tex&quot;&gt;\left| I \right|&lt;/script&gt;. 
Thus the initial point $y_0=\beta$ is not really important for our purposes.&lt;/p&gt;

&lt;p&gt;The smallest (least frequent) interval delimited by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;0,-\alpha,-2\alpha,\ldots,-m\alpha\,,&lt;/script&gt;

&lt;p&gt;in fact corresponds to the one given by $0$ and 
&lt;script type=&quot;math/tex&quot;&gt;\{-q_k\alpha\}&lt;/script&gt;, 
where 
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
q_k(\alpha)\leq m &lt; q_{k+1}(\alpha) %]]&gt;&lt;/script&gt;, 
and has length 
&lt;script type=&quot;math/tex&quot;&gt;\Gamma(\alpha,m) := |q_k \alpha - p_k|&lt;/script&gt;, 
by the Theorem of the &lt;em&gt;Best approximation&lt;/em&gt; section in the previous post.&lt;/p&gt;
</description>
        <pubDate>Thu, 07 Sep 2017 00:00:00 +0200</pubDate>
        <link>https://semidoc.github.io///rotondo-sturmian</link>
        <guid isPermaLink="true">https://semidoc.github.io///rotondo-sturmian</guid>
      </item>
    
      <item>
        <title>Combinatorics of continued fractions</title>
        <description>&lt;p&gt;Hello, the first post of this new academic year is by &lt;a href=&quot;https://www.irif.fr/users/rotondo/index&quot;&gt;Pablo Rotondo&lt;/a&gt; 
who gave a talk at the seminar a few months ago. As there is more to say about 
the subject, this post will probably have a follow-up later.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;In this post we discuss 
&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Continued_fraction&quot;&gt;continued fraction expansions&lt;/a&gt;&lt;/strong&gt;, 
and their statistics.&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Continued fractions are rather ubiquitous, they pop up in various contexts such as: 
the &lt;a href=&quot;https://en.wikipedia.org/wiki/Euclidean_algorithm&quot;&gt;Euclidean Algorithm&lt;/a&gt;, 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Pell%27s_equation&quot;&gt;Pell’s equation&lt;/a&gt; (see 
&lt;a href=&quot;http://www-bcf.usc.edu/~lototsky/PiMuEp/Pell-IMO.pdf&quot;&gt;here&lt;/a&gt; and 
&lt;a href=&quot;http://math.stanford.edu/~jbooher/expos/continued_fractions.pdf&quot;&gt;here&lt;/a&gt;) and 
&lt;a href=&quot;https://en.wikipedia.org/wiki/Diophantine_approximation&quot;&gt;Diophantine approximation&lt;/a&gt;, the approximation of reals by rationals.&lt;/p&gt;

&lt;h3 id=&quot;relation-to-the-euclidean-algorithm-and-definitions&quot;&gt;Relation to the Euclidean algorithm and definitions.&lt;/h3&gt;

&lt;p&gt;Let us briefly see their relation to the Euclidean algorithm as an introduction.&lt;/p&gt;

&lt;p&gt;The Euclidean algorithm allows us to calculate the greatest common divisor ($\gcd$) of 
a pair of positive integers $(x,y)$, by performing successive divisions. Supposing
$x\geq y$, the algorithm proceeds by applying $(x,y)\mapsto (y,x\bmod y)$ until the
smallest entry $y$ is $0$ and the result is then $x$. Its correctness is seen from the fact
that $x\bmod y = x - y \, \lfloor x/y\rfloor$, and therefore $\gcd(x,y)=\gcd(y,x\bmod y)$.&lt;/p&gt;

&lt;p&gt;Let us get to the continued fractions. Given a pair of positive integers $(x,y)$
with $x\geq y$ we may write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{y}{x} = \frac{1}{x/y} = \cfrac{1}{\lfloor x/y \rfloor + \cfrac{x\bmod y}{y} }\,,&lt;/script&gt;

&lt;p&gt;and then continue the procedure with $\cfrac{x\bmod y}{y}$ provided that $x\bmod y \neq 0$. This is
exactly the Euclidean algorithm, and observe that the quotients $\lfloor x/y\rfloor$
that we discard in the algorithm here appear as coefficients.&lt;/p&gt;

&lt;p&gt;Thus the Euclidean produces a continued fraction expansion&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{y}{x} = \cfrac{1}{m_1 + \cfrac{1}{\ddots + \cfrac{1}{m_k} }}\,,&lt;/script&gt;

&lt;p&gt;where the positive integers $m_1,\ldots,m_k$ are the successive quotients in the algorithm.&lt;/p&gt;

&lt;p&gt;More generally, we call any such expansion a continued fraction expansion and even given infinitely many coefficients $m_1,\ldots,m_k,\ldots$ we define&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\cfrac{1}{m_1 + \cfrac{1}{m_2+\ddots} } = \lim_{k\to\infty}\cfrac{1}{m_1 + \cfrac{1}{\ddots + \cfrac{1}{m_k} }}\,,&lt;/script&gt;

&lt;p&gt;whose convergence we do not prove here, but you can find a proof in Kinchin’s book 
(see the reference at the end of the post).&lt;/p&gt;

&lt;p&gt;Rational numbers have exactly two expansions:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{y}{x} = \cfrac{1}{m_1 + \cfrac{1}{\ddots + \cfrac{1}{m_k} }}= \cfrac{1}{m_1 + \cfrac{1}{\ddots + \cfrac{1}{(m_k-1) + \cfrac{1}{1}} }}\,,&lt;/script&gt;

&lt;p&gt;while irrational numbers $\alpha\in (0,1)$ have a unique (infinite) expansion, 
which can be found applying the same Euclidean algorithm (!) to the pair $(1/\alpha,1)$.&lt;/p&gt;

&lt;p&gt;Some remarkable examples  (for a proof see &lt;a href=&quot;https://arxiv.org/abs/math/0601660&quot;&gt;this&lt;/a&gt; 
arXiv note or &lt;a href=&quot;https://topologicalmusings.wordpress.com/2008/08/04/continued-fraction-for-e/&quot;&gt;this&lt;/a&gt;)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{\sqrt{5}-1}{2} = \cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{\ddots}}}\,,&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\qquad e-2 = \cfrac{1}{1+\cfrac{1}{2+\cfrac{1}{1+\cfrac{1}{1+\cfrac{1}{4+\cfrac{1}{1+\ddots}}}}}}\,,&lt;/script&gt;

&lt;p&gt;the last one being made up from the concatenation of the trios $1,2n,1$ for $n=1,2,\ldots$.&lt;/p&gt;

&lt;h3 id=&quot;notations&quot;&gt;Notations&lt;/h3&gt;
&lt;p&gt;Given an irrational number $\alpha \in (0,1)$ with continued fraction expansion&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha  = \cfrac{1}{m_1 + \cfrac{1}{m_2+\ddots} }\,,&lt;/script&gt;

&lt;p&gt;the coefficients $m_1,m_2,\ldots \geq 1$ are called &lt;em&gt;partial quotients&lt;/em&gt; or &lt;em&gt;digits&lt;/em&gt;, while the partial expansions&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{p_k(\alpha)}{q_k(\alpha)} := \cfrac{1}{m_1 + \cfrac{1}{\ddots + \cfrac{1}{m_k}}}\,,&lt;/script&gt;

&lt;p&gt;with 
&lt;script type=&quot;math/tex&quot;&gt;\gcd(p_k(\alpha),q_k(\alpha)) = 1&lt;/script&gt;, 
are known as &lt;em&gt;convergents&lt;/em&gt;. By convention we define $p_0=0$ and $q_0=1$ for every irrational $\alpha\in (0,1)$. The denominators $(q_k(\alpha))_{k\in \mathbb{N}}$ of the convergents are known as the &lt;em&gt;continuants&lt;/em&gt; of $\alpha$.&lt;/p&gt;

&lt;p&gt;Of course, all of these definition can be extended to rational numbers by considering only the meaningful part ($k\leq$ length of the expansion). See &lt;a href=&quot;http://stackoverflow.com/questions/5440688/the-guess-the-number-game-for-arbitrary-rational-numbers&quot;&gt;here&lt;/a&gt; for a particularly interesting application to a game of guessing a rational number!&lt;/p&gt;

&lt;h3 id=&quot;number-of-steps-in-the-euclidean-algorithm&quot;&gt;Number of steps in the Euclidean algorithm.&lt;/h3&gt;

&lt;p&gt;The depth of the continued fraction expansion of a rational number $x/y$ is exactly the number of steps $\ell:=\ell(x,y)$ performed by the Euclidean algorithm on $(x,y)$. To bound $\ell$, we remark that the denominators satisfy the following recurrence relation&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{k+1} = m_{k+1}q_k + q_{k-1}\,,\quad q_0=1,q_{-1}=0\,.&lt;/script&gt;

&lt;p&gt;This is proved by induction, along with the analogous (up to the initial condition) recurrence relation for the numerators $p_k$. 
It is evident from the recurrence relation that $q_k$ is strictly increasing, furthermore&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;q_{k+1} = m_{k+1}q_k + q_{k-1} \geq 2 q_{k-1}\,,&lt;/script&gt;

&lt;p&gt;so that $q_k \geq 2^{\frac{k-1}{2}}$.&lt;/p&gt;

&lt;p&gt;Picking $k=\ell(x,y)$, the previous inequality reads $y\geq 2^{\frac{\ell-1}{2}}$ so that&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\ell(x,y) \leq 1 + 2 \log_2 y\,.&lt;/script&gt;

&lt;h1 id=&quot;classical-continued-fraction-statistics&quot;&gt;Classical Continued Fraction Statistics&lt;/h1&gt;
&lt;p&gt;We have just seen that convergents $q_k(\alpha)$ grow at least exponentially&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;2^{\frac{k-1}{2}} \leq q_k(\alpha)\,,&lt;/script&gt;

&lt;p&gt;we briefly mention that much more precise results are known when we allow $\alpha$ to be almost any irrational in $(0,1)$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; [Lévy]
For almost every $\alpha\in (0,1)$ (w.r.t the Lebesgue -uniform- measure) we have&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lim_{k\to\infty}\frac{1}{k}\log q_k(\alpha) = \frac{\pi^2}{12 \log 2}\,.&lt;/script&gt;

&lt;p&gt;This result is proved by using Ergodic Theory. Continued fractions are naturally associated to the
so called Euclidean Dynamical System arising from the Gauss map&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;T \colon (0,1)\to (0,1) \,,\qquad x\mapsto \left\{\tfrac{1}{x}\right\}\,,&lt;/script&gt;

&lt;p&gt;where ${x}:=x-\lfloor x\rfloor$ is the &lt;em&gt;fractional part&lt;/em&gt; of $x$.&lt;/p&gt;

&lt;p&gt;Interestingly, it is also true that the frequency of $m_j=k$ tends to
$\log_2\left(1+\frac{1}{k(k+2)}\right)$ almost surely as we take more and more quotients.
For more on this read the notes 
&lt;a href=&quot;http://www.maths.manchester.ac.uk/~cwalkden/ergodic-theory/ergodic_theory.pdf&quot;&gt;here&lt;/a&gt; 
or in Khinchin’s book.&lt;/p&gt;

&lt;h1 id=&quot;best-approximations&quot;&gt;Best approximations&lt;/h1&gt;
&lt;p&gt;Convergents are particularly important due to the fact that they provide the ``best’’ approximations to numbers in the following sense&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Definition&lt;/em&gt; [Best approximations of the second kind]
Let $\alpha \in (0,1)$ be a real number. Then the fraction $\tfrac{p}{q}$ with $q&amp;gt;0$ is said to be a best approximation of the second kind for $\alpha$ if and only if&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
|q \alpha - p| &lt; |q^\prime \alpha - p^\prime| %]]&gt;&lt;/script&gt;

&lt;p&gt;for any other fraction $\tfrac{p^\prime}{q^\prime}$ with $0&amp;lt;
q \prime \leq q$.&lt;/p&gt;

&lt;p&gt;Remark that 
&lt;script type=&quot;math/tex&quot;&gt;|q \alpha - p| = \frac{| \alpha - p / q|}{1/q}&lt;/script&gt; so that this ``objective function’’ can be thought of as the error of approximating $\alpha$ by $p/q$, relative to the size of the denominator $q$. We are ready to state the relation with continued fractions&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; [See Khinchin 97]
Best approximations of the second kind are necessarily convergents, and conversely, every convergent is a best approximation of the second kind, with exception of the trivial case of&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\alpha = \frac{1}{2},\qquad \frac{p_0}{q_0} = 0\,.&lt;/script&gt;

&lt;p&gt;Concretely, this means that if we may choose from the set of fractions whose denominators are at most $n$, the best approximation is given by $\frac{p_k(\alpha)}{q_k(\alpha)}$ with $k:= k(\alpha,n)$ is the only index $k$ for which $q_k(\alpha)\leq n &amp;lt; q_{k+1}(\alpha)$.&lt;/p&gt;

&lt;p&gt;We remark that it is the continuants under the condition $q_k(\alpha)\leq n &amp;lt; q_{k+1}(\alpha)$ and $n\to \infty$ that will eventually interest us, rather than the classical fixed depth $k\to \infty$.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References.&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Aleksandr Ya. Khinchin. Continued Fractions.  &lt;em&gt;New York: Dover Publications&lt;/em&gt;, 1997.&lt;/li&gt;
  &lt;li&gt;M. Einsiedler and T. Ward. Ergodic Theory: with a view towards Number Theory. &lt;em&gt;Graduate Texts
in Mathematics. Springer, 2010.&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;N. P. Fogg , V. Berthé, S. Ferenczi , C. Mauduit and Anne Siegel: Substitutions in Dynamics, Arithmetics, and Combinatorics &lt;em&gt;Lecture Notes in Mathematics, Vol. 1794.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 31 Aug 2017 00:00:00 +0200</pubDate>
        <link>https://semidoc.github.io///rotondo-fractions</link>
        <guid isPermaLink="true">https://semidoc.github.io///rotondo-fractions</guid>
      </item>
    
  </channel>
</rss>
